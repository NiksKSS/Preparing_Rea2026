{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea737997",
   "metadata": {},
   "source": [
    " # üîπ 1) –Ω–∞—á–∞–ª—å–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077ee6de",
   "metadata": {},
   "source": [
    "1. –∏–º–ø–æ—Ä—Ç—ã –±–∏–±–ª–∏–æ—Ç–µ–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d38f2fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d30737",
   "metadata": {},
   "source": [
    "2. –ø—Ä–∏–≤–µ–¥–µ–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∫ –æ–¥–Ω–æ–º—É –≤–∏–¥—É –∏ —Ñ–æ—Ä–º–∞—Ç—É —Ç–µ–Ω–∑–æ—Ä–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ac24b96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "basic_tfms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "from torchvision import datasets\n",
    "\n",
    "train_ds = datasets.ImageFolder(\"data_fruits/train\", transform=basic_tfms)\n",
    "val_ds   = datasets.ImageFolder(\"data_fruits/val\",   transform=basic_tfms)\n",
    "test_ds  = datasets.ImageFolder(\"data_fruits/test\",  transform=basic_tfms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d246ca42",
   "metadata": {},
   "source": [
    "3. —Å–æ—â–¥–∞–µ–º ImageFolder, –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–µ–Ω, —á—Ç–æ–±—ã –Ω–µ –ø–∏—Å–∞—Ç—å —Å–≤–æ–π –∫–æ–¥ –æ–±—Ö–æ–¥–∞ –ø–∞–ø–æ–∫\n",
    "ImageFolder:\n",
    "- —Å–º–æ—Ç—Ä–∏—Ç –Ω–∞ –ø–æ–¥–ø–∞–ø–∫–∏ –≤ train/val/test,\n",
    "- —Å—á–∏—Ç–∞–µ—Ç –∫–∞–∂–¥—É—é –ø–æ–¥–ø–∞–ø–∫—É –æ—Ç–¥–µ–ª—å–Ω—ã–º –∫–ª–∞—Å—Å–æ–º,\n",
    "- –∫–∞–∂–¥–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –¥–∞—ë—Ç –Ω–æ–º–µ—Ä –∫–ª–∞—Å—Å–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fd4e1891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "train_ds = datasets.ImageFolder(root=\"data_fruits/train\", transform=basic_tfms)\n",
    "val_ds   = datasets.ImageFolder(root=\"data_fruits/val\",   transform=basic_tfms)\n",
    "test_ds  = datasets.ImageFolder(root=\"data_fruits/test\",  transform=basic_tfms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d3d3e5",
   "metadata": {},
   "source": [
    "4. DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "138e1ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_dl   = DataLoader(val_ds, batch_size=32, shuffle=False)\n",
    "test_dl  = DataLoader(test_ds, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b463ebe",
   "metadata": {},
   "source": [
    "# üîπ 2) –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π ML –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "\n",
    "1 –≤–∞—Ä–∏–∞–Ω—Ç \n",
    "1. –ü—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É –≤ —á–∏—Å–ª–æ–≤–æ–π –≤–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\n",
    "—Ç.–µ\n",
    "    - –ø–µ—Ä–µ–≤–æ–¥–∏–º –∫–∞—Ä—Ç–∏–Ω–∫—É –≤ RGB;\n",
    "    - —É–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä (–¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏);\n",
    "    - —Å—á–∏—Ç–∞–µ–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É –ø–æ –∫–∞–∂–¥–æ–º—É –∫–∞–Ω–∞–ª—É (R, G, B);\n",
    "    - —Å–æ–µ–¥–∏–Ω—è–µ–º —Ç—Ä–∏ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –≤ –æ–¥–∏–Ω –≤–µ–∫—Ç–æ—Ä.\n",
    "2. –û–±—É—á–∏—Ç—å –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, SVM) –Ω–∞ —ç—Ç–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö.\n",
    "3. –ü–æ–ª—É—á–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ (accuracy, precision, recall, F1).\n",
    "\n",
    "2 –≤–∞—Ä–∏–∞–Ω—Ç\n",
    "–ø—Ä–æ—Å—Ç–æ –±–æ–ª—å—à–µ —Ä–∞–∑–º–µ—Ä + flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca0e206",
   "metadata": {},
   "source": [
    "1 –≤–∞—Ä–∏–∞–Ω—Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7b2f0609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "class_names = sorted([p.name for p in Path(\"data_fruits/train\").iterdir() if p.is_dir()])\n",
    "\n",
    "def img_features1(path, bins=16):\n",
    "    \"\"\"\n",
    "    –ò–∑ –æ–¥–Ω–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–∏ –¥–µ–ª–∞–µ–º –≤–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\n",
    "    - –ø–µ—Ä–µ–≤–æ–¥–∏–º –∫–∞—Ä—Ç–∏–Ω–∫—É –≤ RGB;\n",
    "    - —É–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä (–¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏);\n",
    "    - —Å—á–∏—Ç–∞–µ–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É –ø–æ –∫–∞–∂–¥–æ–º—É –∫–∞–Ω–∞–ª—É (R, G, B);\n",
    "    - —Å–æ–µ–¥–∏–Ω—è–µ–º —Ç—Ä–∏ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –≤ –æ–¥–∏–Ω –≤–µ–∫—Ç–æ—Ä.\n",
    "    - –¥–æ–±–∞–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –ø–æ –∫–∞–∂–¥–æ–º—É –∫–∞–Ω–∞–ª—É (–µ—â—ë 6 —á–∏—Å–µ–ª)\n",
    "    \"\"\"\n",
    "    # 1) RGB\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "    # 2) —É–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä\n",
    "    img = img.resize((128, 128))\n",
    "\n",
    "    # 3) –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –ø–æ –∫–∞–Ω–∞–ª–∞–º\n",
    "    arr = np.array(img)\n",
    "    hist_list = []\n",
    "    for ch in range(3): \n",
    "        channel = arr[..., ch]\n",
    "        hist, _ = np.histogram(\n",
    "            channel,\n",
    "            bins=bins,\n",
    "            range=(0, 256),\n",
    "            density=True\n",
    "        )\n",
    "        hist_list.append(hist)\n",
    "\n",
    "\n",
    "    means = arr.mean(axis=(0, 1))\n",
    "    stds  = arr.std(axis=(0, 1))\n",
    "\n",
    "    # 4) –æ–¥–∏–Ω –æ–±—â–∏–π –≤–µ–∫—Ç–æ—Ä\n",
    "    features = np.concatenate(hist_list + [means, stds])\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be427229",
   "metadata": {},
   "source": [
    "2 –≤–∞—Ä–∏–∞–Ω—Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "274c9f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted([p.name for p in Path(\"data_fruits/train\").iterdir() if p.is_dir()])\n",
    "train_dir = Path(\"data_fruits/train\")\n",
    "\n",
    "def img_features2(path):\n",
    "    \"\"\"\n",
    "    –ü—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –∫–∞—Ä—Ç–∏–Ω–∫–∏:\n",
    "    - RGB\n",
    "    - —É–º–µ–Ω—å—à–∞–µ–º –¥–æ 32x32\n",
    "    - —Ä–∞—Å–ø–ª—é—â–∏–≤–∞–µ–º –≤ –æ–¥–∏–Ω –≤–µ–∫—Ç–æ—Ä (32*32*3 = 3072 —á–∏—Å–ª–∞)\n",
    "    \"\"\"\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    img = img.resize((32, 32))\n",
    "    arr = np.array(img) / 255.0\n",
    "    return arr.flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeec4f2",
   "metadata": {},
   "source": [
    "–¥–µ–ª–∞–µ–º –º–∞—Ç—Ä–∏—Ü—ã x –∏ y –¥–ª—è 2 –≤–∞—Ä–∏–∞–Ω—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ecf2b447",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "\n",
    "for cls_idx, cls in enumerate(class_names):\n",
    "    folder = train_dir / cls\n",
    "    for name in os.listdir(folder):\n",
    "        if name.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            X.append(img_features2(folder / name))\n",
    "            y.append(cls_idx)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a1dd70",
   "metadata": {},
   "source": [
    "–¥–µ–ª–∞–µ–º –º–∞—Ç—Ä–∏—Ü—ã x –∏ y –¥–ª—è 1 –≤–∞—Ä–∏–∞–Ω—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "29bcee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "\n",
    "for cls_idx, cls in enumerate(class_names):\n",
    "    folder = Path(\"data_fruits/train\") / cls\n",
    "    for name in os.listdir(folder):\n",
    "        if name.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            path = folder / name\n",
    "            X.append(img_features1(path))  # –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "            y.append(cls_idx)  # –Ω–æ–º–µ—Ä –∫–ª–∞—Å—Å–∞\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55f9e4b",
   "metadata": {},
   "source": [
    "–¥–µ–ª–∏–º –Ω–∞ train –∏ val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "23db1a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7b46ed",
   "metadata": {},
   "source": [
    "–æ–±—É—á–∏–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccb6ffc",
   "metadata": {},
   "source": [
    "1. –ª–æ–≥–∏—Å—Ç–∏—á—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6e3349f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "     apple fruit       0.50      0.20      0.29         5\n",
      "    banana fruit       1.00      0.60      0.75         5\n",
      "    cherry fruit       0.50      0.33      0.40         6\n",
      "   chickoo fruit       0.50      0.33      0.40         6\n",
      "    grapes fruit       0.50      0.67      0.57         6\n",
      "      kiwi fruit       0.45      1.00      0.62         5\n",
      "     mango fruit       0.00      0.00      0.00         5\n",
      "    orange fruit       0.44      0.80      0.57         5\n",
      "strawberry fruit       0.50      0.60      0.55         5\n",
      "\n",
      "        accuracy                           0.50        48\n",
      "       macro avg       0.49      0.50      0.46        48\n",
      "    weighted avg       0.49      0.50      0.46        48\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml-env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred_lr = log_reg.predict(X_val)\n",
    "print(classification_report(y_val, y_pred_lr, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d802ac64",
   "metadata": {},
   "source": [
    "—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –æ—á–µ–Ω—å —Ç–∫ –¥–∞–Ω–Ω—ã—Ö –æ—á–µ–Ω—å –º–∞–ª–æ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d977902",
   "metadata": {},
   "source": [
    "2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eb3f6daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "     apple fruit       0.00      0.00      0.00         5\n",
      "    banana fruit       1.00      0.60      0.75         5\n",
      "    cherry fruit       0.00      0.00      0.00         6\n",
      "   chickoo fruit       0.17      0.17      0.17         6\n",
      "    grapes fruit       0.55      1.00      0.71         6\n",
      "      kiwi fruit       0.50      0.80      0.62         5\n",
      "     mango fruit       0.00      0.00      0.00         5\n",
      "    orange fruit       0.43      0.60      0.50         5\n",
      "strawberry fruit       0.50      1.00      0.67         5\n",
      "\n",
      "        accuracy                           0.46        48\n",
      "       macro avg       0.35      0.46      0.38        48\n",
      "    weighted avg       0.34      0.46      0.37        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(kernel=\"rbf\", C=5, gamma=\"scale\")\n",
    "svm_clf.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred_svm = svm_clf.predict(X_val)\n",
    "print(classification_report(y_val, y_pred_svm, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904edad7",
   "metadata": {},
   "source": [
    "3. random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a64ab805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "     apple fruit       0.33      0.20      0.25         5\n",
      "    banana fruit       0.80      0.80      0.80         5\n",
      "    cherry fruit       0.25      0.17      0.20         6\n",
      "   chickoo fruit       0.43      0.50      0.46         6\n",
      "    grapes fruit       0.50      0.67      0.57         6\n",
      "      kiwi fruit       0.67      0.80      0.73         5\n",
      "     mango fruit       0.60      0.60      0.60         5\n",
      "    orange fruit       1.00      0.40      0.57         5\n",
      "strawberry fruit       0.62      1.00      0.77         5\n",
      "\n",
      "        accuracy                           0.56        48\n",
      "       macro avg       0.58      0.57      0.55        48\n",
      "    weighted avg       0.57      0.56      0.54        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_clf.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred_rf = rf_clf.predict(X_val)\n",
    "print(classification_report(y_val, y_pred_rf, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebc91df",
   "metadata": {},
   "source": [
    "üîπ 3) –ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ \n",
    "\n",
    "–Ω–∞ –ø—Ä–∏–º–µ—Ä–µ ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1381d4f6",
   "metadata": {},
   "source": [
    "- –≤—ã–±–∏—Ä–∞–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (`device`);\n",
    "- —Å—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤ (`num_classes`);\n",
    "- –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω—É–∂–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "33fbdba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# device: –∫—É–¥–∞ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –º–æ–¥–µ–ª—å –∏ –¥–∞–Ω–Ω—ã–µ (cuda, –µ—Å–ª–∏ –µ—Å—Ç—å GPU, –∏–Ω–∞—á–µ cpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# num_classes: —Å–∫–æ–ª—å–∫–æ —É –Ω–∞—Å —Ä–∞–∑–Ω—ã—Ö —Ñ—Ä—É–∫—Ç–æ–≤ (–∫–ª–∞—Å—Å–æ–≤)\n",
    "num_classes = len(class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467f6dba",
   "metadata": {},
   "source": [
    "–°–æ–∑–¥–∞—ë–º ResNet18 (–º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–∞–∫–∂–µ ResNet50 / ResNet101 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5cd62bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —Å–æ–∑–¥–∞—ë–º ResNet18 –±–µ–∑ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –≤–µ—Å–æ–≤\n",
    "resnet = models.resnet18(weights=None)\n",
    "\n",
    "#resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT) - –æ–±—É—á–µ–Ω–∏–µ —Å –≤–µ—Å–∞–º–∏(–º–æ–π –Ω–æ—É—Ç –ø—Ä–æ—Å—Ç–æ –Ω–µ —Ç—è–Ω–µ—Ç)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba60e0fb",
   "metadata": {},
   "source": [
    "–ú–µ–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π –ø–æ–¥ –Ω–∞—à–∏ –∫–ª–∞—Å—Å—ã\n",
    "\n",
    "- `resnet.fc` ‚Äî –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π.\n",
    "- –£ –Ω–µ–≥–æ –µ—Å—Ç—å –≤—Ö–æ–¥–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å `in_features`.\n",
    "- –ó–∞–º–µ–Ω—è–µ–º –µ–≥–æ –Ω–∞ `nn.Linear(in_features, num_classes)`, —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å –º–æ–≥–ª–∞ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞—à–∏ –∫–ª–∞—Å—Å—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "60f02605",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed10ae7",
   "metadata": {},
   "source": [
    "–ü–µ—Ä–µ–Ω–æ—Å –º–æ–¥–µ–ª–∏ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–±—É—á–µ–Ω–∏—è\n",
    "\n",
    "- –ü–µ—Ä–µ–Ω–æ—Å–∏–º –º–æ–¥–µ–ª—å –Ω–∞ `device`.\n",
    "- –ó–∞–¥–∞—ë–º:\n",
    "  - `criterion` ‚Äî —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å (CrossEntropyLoss –¥–ª—è –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ–π –∑–∞–¥–∞—á–∏).\n",
    "  - `optimizer_resnet` ‚Äî –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä Adam —Å –º–∞–ª–µ–Ω—å–∫–∏–º —à–∞–≥–æ–º –æ–±—É—á–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "47a6dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ø–µ—Ä–µ–Ω–æ—Å–∏–º –º–æ–¥–µ–ª—å –Ω–∞ GPU/CPU\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "# —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å: —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –ª–æ–≥–∏—Ç—ã –∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –º–µ—Ç–∫–∏\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä: Adam, –æ–±—É—á–∞–µ–º –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏\n",
    "optimizer_resnet = optim.Adam(\n",
    "    resnet.parameters(),\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-4,   # —ç—Ç–æ L2‚Äë—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è, –æ–Ω–∞ —à—Ç—Ä–∞—Ñ—É–µ—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ –≤–µ—Å–∞ –∏ –ø–æ–º–æ–≥–∞–µ—Ç –±–æ—Ä–æ—Ç—å—Å—è —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914e0581",
   "metadata": {},
   "source": [
    "–æ–±—É—á–∞–µ–º —ç–ø–æ—Ö—É\n",
    "–ù–∞ –≤—Ö–æ–¥:\n",
    "- `model` ‚Äî –Ω–∞—à–∞ ResNet18;\n",
    "- `loader` ‚Äî train_dl (–±–∞—Ç—á–∏ –∫–∞—Ä—Ç–∏–Ω–æ–∫ –∏ –º–µ—Ç–æ–∫);\n",
    "- `optimizer` ‚Äî –æ–±—ä–µ–∫—Ç Adam.\n",
    "\n",
    "–ü—Ä–æ—Ü–µ—Å—Å:\n",
    "1. –ü–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è `model.train()`.\n",
    "2. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –±–∞—Ç—á–∞:\n",
    "   - –ø–µ—Ä–µ–Ω–æ—Å–∏–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ `device`;\n",
    "   - –æ–±–Ω—É–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã;\n",
    "   - —Å—á–∏—Ç–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (`logits`);\n",
    "   - —Å—á–∏—Ç–∞–µ–º loss;\n",
    "   - —Å—á–∏—Ç–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã (`backward`);\n",
    "   - –¥–µ–ª–∞–µ–º —à–∞–≥ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ (`step`);\n",
    "   - –∫–æ–ø–∏–º loss –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–µ—Ä–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤.\n",
    "3. –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ä–µ–¥–Ω–∏–π loss –∏ accuracy –ø–æ –≤—Å–µ–π —ç–ø–æ—Ö–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f8710752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer):\n",
    "    model.train()     \n",
    "\n",
    "    total_loss = 0.0             \n",
    "    total_correct = 0        \n",
    "    total = 0                        \n",
    "\n",
    "    for images, labels in loader:\n",
    "        # –ø–µ—Ä–µ–Ω–æ—Å–∏–º –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∏ –º–µ—Ç–∫–∏ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # —à–∞–≥ 1: –æ–±–Ω—É–ª—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # —à–∞–≥ 2: –ø—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ (forward)\n",
    "        logits = model(images)\n",
    "\n",
    "        # —à–∞–≥ 3: —Å—á–∏—Ç–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        # —à–∞–≥ 4: –æ–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –æ—à–∏–±–∫–∏\n",
    "        loss.backward()\n",
    "\n",
    "        # —à–∞–≥ 5: –æ–±–Ω–æ–≤–ª—è–µ–º –≤–µ—Å–∞\n",
    "        optimizer.step()\n",
    "\n",
    "        # —Å—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –±–∞—Ç—á—É\n",
    "        batch_size = images.size(0)\n",
    "        total_loss += loss.item() * batch_size\n",
    "\n",
    "        # –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å = –∏–Ω–¥–µ–∫—Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –ª–æ–≥–∏—Ç–∞\n",
    "        preds = logits.argmax(1)\n",
    "        total_correct += (preds == labels).sum().item()\n",
    "        total += batch_size\n",
    "\n",
    "    # —Å—Ä–µ–¥–Ω–∏–π loss –∏ accuracy –ø–æ —ç–ø–æ—Ö–µ\n",
    "    avg_loss = total_loss / total\n",
    "    avg_acc = total_correct / total\n",
    "    return avg_loss, avg_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec623c7",
   "metadata": {},
   "source": [
    "–æ—Ü–µ–Ω–∫–∞\n",
    "–ù–∞ –≤—Ö–æ–¥:\n",
    "- `model` ‚Äî ResNet18;\n",
    "- `loader` ‚Äî val_dl –∏–ª–∏ test_dl.\n",
    "\n",
    "–ü—Ä–æ—Ü–µ—Å—Å:\n",
    "1. –ü–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏ `model.eval()`.\n",
    "2. –û—Ç–∫–ª—é—á–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã `torch.no_grad()`.\n",
    "3. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –±–∞—Ç—á–∞:\n",
    "   - —Å—á–∏—Ç–∞–µ–º loss –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è;\n",
    "   - –∫–æ–ø–∏–º loss –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–µ—Ä–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤;\n",
    "   - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –º–µ—Ç–∫–∏ –∏ –≤—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è.\n",
    "4. –í–æ–∑–≤—Ä–∞—â–∞–µ–º:\n",
    "   - —Å—Ä–µ–¥–Ω–∏–π loss,\n",
    "   - accuracy,\n",
    "   - –º–∞—Å—Å–∏–≤ –≤—Å–µ—Ö –∏—Å—Ç–∏–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ `y_true`,\n",
    "   - –º–∞—Å—Å–∏–≤ –≤—Å–µ—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π `y_pred`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cc8f1af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()      \n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            batch_size = images.size(0)\n",
    "            total_loss += loss.item() * batch_size\n",
    "\n",
    "            preds = logits.argmax(1)\n",
    "            total_correct += (preds == labels).sum().item()\n",
    "            total += batch_size\n",
    "\n",
    "            # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –æ—Ç—á—ë—Ç–æ–≤\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    avg_acc = total_correct / total\n",
    "    y_true = np.concatenate(all_labels)\n",
    "    y_pred = np.concatenate(all_preds)\n",
    "    return avg_loss, avg_acc, y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a0d9cd",
   "metadata": {},
   "source": [
    "–û–±—É—á–µ–Ω–∏–µ ResNet18 –ø–æ —ç–ø–æ—Ö–∞–º\n",
    "\n",
    "- `num_epochs` ‚Äî —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –ø—Ä–æ—Ö–æ–¥–∏–º –ø–æ train_dl.\n",
    "- –ù–∞ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–µ:\n",
    "  - —Å—á–∏—Ç–∞–µ–º `train_loss`, `train_acc` –Ω–∞ train_dl;\n",
    "  - —Å—á–∏—Ç–∞–µ–º `val_loss`, `val_acc` –Ω–∞ val_dl;\n",
    "  - –ø–µ—á–∞—Ç–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6d4e7008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResNet] Epoch 1/5 | train_loss=2.0716, train_acc=0.234 | val_loss=2.3413, val_acc=0.111\n",
      "[ResNet] Epoch 2/5 | train_loss=1.2909, train_acc=0.586 | val_loss=2.9452, val_acc=0.111\n",
      "[ResNet] Epoch 3/5 | train_loss=1.0598, train_acc=0.678 | val_loss=4.4992, val_acc=0.111\n",
      "[ResNet] Epoch 4/5 | train_loss=0.7797, train_acc=0.774 | val_loss=5.0584, val_acc=0.111\n",
      "[ResNet] Epoch 5/5 | train_loss=0.6064, train_acc=0.837 | val_loss=4.4047, val_acc=0.185\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5  # –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(resnet, train_dl, optimizer_resnet)\n",
    "    val_loss, val_acc, _, _ = evaluate(resnet, val_dl)\n",
    "\n",
    "    print(\n",
    "        f\"[ResNet] Epoch {epoch+1}/{num_epochs} | \"\n",
    "        f\"train_loss={train_loss:.4f}, train_acc={train_acc:.3f} | \"\n",
    "        f\"val_loss={val_loss:.4f}, val_acc={val_acc:.3f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab57f16a",
   "metadata": {},
   "source": [
    "–§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ\n",
    "\n",
    "- —Å—á–∏—Ç–∞–µ–º `test_loss` –∏ `test_acc` –Ω–∞ `test_dl`;\n",
    "- —Å—Ç—Ä–æ–∏–º `classification_report` (precision, recall, F1 –ø–æ –∫–∞–∂–¥–æ–º—É –∫–ª–∞—Å—Å—É);\n",
    "- –ø–æ–ª—É—á–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É –æ—à–∏–±–æ–∫ `confusion_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "30a7aa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18 test_loss: 4.7167766998554095\n",
      "ResNet18 test_acc : 0.1724137931034483\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "     apple fruit       0.00      0.00      0.00         7\n",
      "    banana fruit       1.00      0.67      0.80         6\n",
      "    cherry fruit       0.00      0.00      0.00         7\n",
      "   chickoo fruit       0.12      1.00      0.21         6\n",
      "    grapes fruit       0.00      0.00      0.00         7\n",
      "      kiwi fruit       0.00      0.00      0.00         6\n",
      "     mango fruit       0.00      0.00      0.00         6\n",
      "    orange fruit       0.00      0.00      0.00         6\n",
      "strawberry fruit       0.00      0.00      0.00         7\n",
      "\n",
      "        accuracy                           0.17        58\n",
      "       macro avg       0.12      0.19      0.11        58\n",
      "    weighted avg       0.12      0.17      0.10        58\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml-env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/envs/ml-env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/envs/ml-env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 7, 0, 0, 0, 0, 0],\n",
       "       [0, 4, 0, 1, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 7, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 6, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 7, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 6, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 6, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 4, 0, 0, 2, 0, 0],\n",
       "       [0, 0, 0, 7, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_acc, y_true_res, y_pred_res = evaluate(resnet, test_dl)\n",
    "\n",
    "print(\"ResNet18 test_loss:\", test_loss)\n",
    "print(\"ResNet18 test_acc :\", test_acc)\n",
    "\n",
    "print(classification_report(\n",
    "    y_true_res,\n",
    "    y_pred_res,\n",
    "    target_names=class_names\n",
    "))\n",
    "\n",
    "cm_resnet = confusion_matrix(y_true_res, y_pred_res)\n",
    "cm_resnet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc57ec9",
   "metadata": {},
   "source": [
    "–ø–ª–æ—Ö–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–∫ –Ω–µ—Ç –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –≤–µ—Å–æ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b874064f",
   "metadata": {},
   "source": [
    "# –¢–∞–∫–∂–µ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å  EfficientNet-B0 –∏–ª–∏ Vision Transformer ViT-B/16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccc1e21",
   "metadata": {},
   "source": [
    "# üîπ –ú–µ—Ç—Ä–∏–∫–∏ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "229f054b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1724137931034483\n",
      "Macro precision: 0.12418300653594772\n",
      "Macro recall   : 0.18518518518518517\n",
      "Macro F1       : 0.11228070175438597\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "     apple fruit       0.00      0.00      0.00         7\n",
      "    banana fruit       1.00      0.67      0.80         6\n",
      "    cherry fruit       0.00      0.00      0.00         7\n",
      "   chickoo fruit       0.12      1.00      0.21         6\n",
      "    grapes fruit       0.00      0.00      0.00         7\n",
      "      kiwi fruit       0.00      0.00      0.00         6\n",
      "     mango fruit       0.00      0.00      0.00         6\n",
      "    orange fruit       0.00      0.00      0.00         6\n",
      "strawberry fruit       0.00      0.00      0.00         7\n",
      "\n",
      "        accuracy                           0.17        58\n",
      "       macro avg       0.12      0.19      0.11        58\n",
      "    weighted avg       0.12      0.17      0.10        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "# accuracy \n",
    "acc = accuracy_score(y_true_res, y_pred_res)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "# macro precision/recall/F1\n",
    "prec = precision_score(y_true_res, y_pred_res, average=\"macro\", zero_division=0)\n",
    "rec  = recall_score(y_true_res, y_pred_res, average=\"macro\", zero_division=0)\n",
    "f1   = f1_score(y_true_res, y_pred_res, average=\"macro\", zero_division=0)\n",
    "\n",
    "print(\"Macro precision:\", prec)\n",
    "print(\"Macro recall   :\", rec)\n",
    "print(\"Macro F1       :\", f1)\n",
    "\n",
    "# –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á—ë—Ç –ø–æ –∫–∞–∂–¥–æ–º—É –∫–ª–∞—Å—Å—É\n",
    "print(classification_report(y_true_res, y_pred_res, target_names=class_names, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672fb27c",
   "metadata": {},
   "source": [
    "- accuracy_score –¥–∞—ë—Ç –æ–±—â—É—é –¥–æ–ª—é –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤.\n",
    "\n",
    "- precision_score/recall_score/f1_score —Å average=\"macro\" –¥–∞—é—Ç —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –∫–ª–∞—Å—Å–∞–º.\n",
    "\n",
    "- –î–ª—è **accuracy, precision, recall, F1**: –≤—Å–µ–≥–¥–∞ **—á–µ–º –≤—ã—à–µ, —Ç–µ–º –ª—É—á—à–µ** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
