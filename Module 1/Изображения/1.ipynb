{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d39509",
   "metadata": {},
   "source": [
    "#  –ü–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç: –†–∞–±–æ—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –≤ –∑–∞–¥–∞—á–∞—Ö –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞  \n",
    "*–î–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∫ —á–µ–º–ø–∏–æ–Ω–∞—Ç—É  (–Ω–∞ –ø—Ä–∏–º–µ—Ä–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ ¬´Dog Breed Image Dataset¬ª)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4853dfb6",
   "metadata": {},
   "source": [
    "## üîπ –°–ø–æ—Å–æ–±—ã –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "\n",
    "–ü–µ—Ä–µ–¥ —Ç–µ–º –∫–∞–∫ –ø—Ä–∏—Å—Ç—É–ø–∏—Ç—å –∫ –∑–∞–≥—Ä—É–∑–∫–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –≤–∞–∂–Ω–æ –ø–æ–Ω—è—Ç—å, **–∫–∞–∫ –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω—ã –¥–∞–Ω–Ω—ã–µ**. –û—Ç —ç—Ç–æ–≥–æ –∑–∞–≤–∏—Å–∏—Ç —Å–ø–æ—Å–æ–± –∏—Ö —Å—á–∏—Ç—ã–≤–∞–Ω–∏—è –∏ –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏. –°—É—â–µ—Å—Ç–≤—É–µ—Ç –¥–≤–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–∞, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e6a154",
   "metadata": {},
   "source": [
    "###  –°–ø–æ—Å–æ–± 1: –ö–∞–∂–¥–∞—è –ø–∞–ø–∫–∞ ‚Äî –æ—Ç–¥–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å (–æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç)\n",
    "\n",
    "–≠—Ç–æ **–Ω–∞–∏–±–æ–ª–µ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã–π –∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Å–ø–æ—Å–æ–±** –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. \n",
    "\n",
    "**–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –≤—ã–≥–ª—è–¥–∏—Ç —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:**\n",
    "```\n",
    "dog_breeds/\n",
    "‚îú‚îÄ‚îÄ Labrador/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ 001.jpg\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ 002.jpg\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "‚îú‚îÄ‚îÄ Beagle/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ 101.jpg\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "‚îú‚îÄ‚îÄ Poodle/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "‚îî‚îÄ‚îÄ ...\n",
    "```\n",
    "\n",
    "–í —ç—Ç–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ:\n",
    "- –ù–∞–∑–≤–∞–Ω–∏–µ –∫–∞–∂–¥–æ–π –ø–æ–¥–ø–∞–ø–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `Labrador`) **—è–≤–ª—è–µ—Ç—Å—è –º–µ—Ç–∫–æ–π –∫–ª–∞—Å—Å–∞**.\n",
    "- –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –Ω–∞—Ö–æ–¥—è—â–∏–µ—Å—è –≤–Ω—É—Ç—Ä–∏ —ç—Ç–æ–π –ø–æ–¥–ø–∞–ø–∫–∏, **–æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ –¥–∞–Ω–Ω–æ–º—É –∫–ª–∞—Å—Å—É**.\n",
    "- –ù–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π ‚Äî —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫ —Å–∞–º–∞ –ø–æ —Å–µ–±–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å—é –Ω–µ–æ–±—Ö–æ–¥–∏–º—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.\n",
    "\n",
    "**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ —ç—Ç–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞:**\n",
    "- –ü—Ä–æ—Å—Ç–æ—Ç–∞ –∏ –∏–Ω—Ç—É–∏—Ç–∏–≤–Ω–∞—è –ø–æ–Ω—è—Ç–Ω–æ—Å—Ç—å.\n",
    "- –ü—Ä—è–º–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –≤–µ–¥—É—â–∏–º–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞–º–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, —Ç–∞–∫–∏–º–∏ –∫–∞–∫ PyTorch (`torchvision.datasets.ImageFolder`), TensorFlow (`tf.keras.utils.image_dataset_from_directory`) –∏ YOLO (Ultralytics).\n",
    "- –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∏—Å–∫ –æ—à–∏–±–æ–∫ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a56b8ef",
   "metadata": {},
   "source": [
    "###  –°–ø–æ—Å–æ–± 2: –ú–µ—Ç–∫–∞ –∫–ª–∞—Å—Å–∞ —É–∫–∞–∑–∞–Ω–∞ –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞\n",
    "\n",
    "–í –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å–ª—É—á–∞—è—Ö, –æ—Å–æ–±–µ–Ω–Ω–æ –≤ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∏–ª–∏ –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö, –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –º–æ–≥—É—Ç –Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –≤ **–æ–¥–Ω–æ–π –æ–±—â–µ–π –ø–∞–ø–∫–µ**, –∞ –º–µ—Ç–∫–∞ –∫–ª–∞—Å—Å–∞ **–∫–æ–¥–∏—Ä—É–µ—Ç—Å—è –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞**.\n",
    "\n",
    "**–ü—Ä–∏–º–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã:**\n",
    "```\n",
    "images/\n",
    "‚îú‚îÄ‚îÄ Labrador_001.jpg\n",
    "‚îú‚îÄ‚îÄ Beagle_002.jpg\n",
    "‚îú‚îÄ‚îÄ Poodle_003.jpg\n",
    "‚îî‚îÄ‚îÄ ...\n",
    "```\n",
    "\n",
    "–ó–¥–µ—Å—å:\n",
    "- –ö–ª–∞—Å—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä, `Labrador`) —è–≤–ª—è–µ—Ç—Å—è **–ø–µ—Ä–≤–æ–π —á–∞—Å—Ç—å—é –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞**, –æ—Ç–¥–µ–ª—ë–Ω–Ω–æ–π –æ—Ç –æ—Å—Ç–∞–ª—å–Ω–æ–≥–æ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ —Å–∏–º–≤–æ–ª–æ–º –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏—è `_`.\n",
    "- –ß—Ç–æ–±—ã –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–µ—Ç–∫—É, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ **–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–º—è —Ñ–∞–π–ª–∞** –∏ –∏–∑–≤–ª–µ—á—å –∏–∑ –Ω–µ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é —á–∞—Å—Ç—å.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0da4612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# –î–ª—è CNN (–Ω–µ–π—Ä–æ—Å–µ—Ç–∏)\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13db8613",
   "metadata": {},
   "source": [
    "## üîπ  –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a43eb8",
   "metadata": {},
   "source": [
    "### –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ –ø–∞–ø–∫–∞–º (–æ—Å–Ω–æ–≤–Ω–æ–π —Å–ø–æ—Å–æ–±)\n",
    "–≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–ª–∞—Å—Å –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –ø–∞–ø–∫–∏ –∏ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç —Ä—É—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏–º—ë–Ω —Ñ–∞–π–ª–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cfcb2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: 967\n",
      "–ö–ª–∞—Å—Å—ã: ['Beagle' 'Boxer' 'Bulldog' 'Dachshund' 'German_Shepherd'\n",
      " 'Golden_Retriever' 'Labrador_Retriever' 'Poodle' 'Rottweiler'\n",
      " 'Yorkshire_Terrier']\n",
      "label\n",
      "Beagle                100\n",
      "Boxer                 100\n",
      "Bulldog               100\n",
      "Poodle                100\n",
      "Yorkshire_Terrier     100\n",
      "Dachshund              96\n",
      "German_Shepherd        96\n",
      "Labrador_Retriever     95\n",
      "Golden_Retriever       91\n",
      "Rottweiler             89\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#(–∫–ª–∞—Å—Å = –∏–º—è –ø–∞–ø–∫–∏)\n",
    "\n",
    "DATASET_DIR = Path(\"dataset\")\n",
    "\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n",
    "\n",
    "rows = []\n",
    "for class_dir in sorted([p for p in DATASET_DIR.iterdir() if p.is_dir()]):\n",
    "    label = class_dir.name\n",
    "    for img_path in class_dir.rglob(\"*\"):\n",
    "        if img_path.suffix.lower() in IMG_EXTS:\n",
    "            rows.append({\"path\": str(img_path), \"label\": label})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(\"–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:\", len(df))\n",
    "print(\"–ö–ª–∞—Å—Å—ã:\", df[\"label\"].unique())\n",
    "print(df[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd042d06",
   "metadata": {},
   "source": [
    "### –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ –∏–º–µ–Ω–∞–º —Ñ–∞–π–ª–æ–≤\n",
    "–î–ª—è –º–µ–Ω–µ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞, –≥–¥–µ –º–µ—Ç–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞, —Ä–µ–∞–ª–∏–∑—É–µ–º –æ—Ç–¥–µ–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b020686b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: 967\n",
      "–ö–ª–∞—Å—Å—ã: ['Rottweiler' 'Dachshund' 'Yorkshire Terrier' 'Beagle' 'Golden Retriever'\n",
      " 'Poodle' 'Labrador Retriever' 'German Shepherd' 'Boxer' 'Bulldog']\n",
      "label\n",
      "Yorkshire Terrier     100\n",
      "Beagle                100\n",
      "Poodle                100\n",
      "Boxer                 100\n",
      "Bulldog               100\n",
      "Dachshund              96\n",
      "German Shepherd        96\n",
      "Labrador Retriever     95\n",
      "Golden Retriever       91\n",
      "Rottweiler             89\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "DATASET_DIR_FLAT = Path(\"dataset\")  \n",
    "\n",
    "def label_from_filename(filename: str) -> str:\n",
    "    stem = Path(filename).stem\n",
    "    return re.split(r\"[_-]\", stem)[0]\n",
    "\n",
    "rows2 = []\n",
    "for img_path in DATASET_DIR_FLAT.rglob(\"*\"):\n",
    "    if img_path.is_file() and img_path.suffix.lower() in IMG_EXTS:\n",
    "        rows2.append({\"path\": str(img_path), \"label\": label_from_filename(img_path.name)})\n",
    "\n",
    "df2 = pd.DataFrame(rows2)\n",
    "print(\"–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:\", len(df2))\n",
    "print(\"–ö–ª–∞—Å—Å—ã:\", df2[\"label\"].unique())\n",
    "print(df2[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20269e05",
   "metadata": {},
   "source": [
    "## üîπ  –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "\n",
    "–ü–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ **–ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –∫ –ø–æ–¥–∞—á–µ –≤ –º–æ–¥–µ–ª—å**. –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å:\n",
    "\n",
    "- –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω—ã –≤ –µ–¥–∏–Ω—ã–π —Ü–≤–µ—Ç–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç (–æ–±—ã—á–Ω–æ RGB),\n",
    "- –ü—Ä–∏–≤–µ–¥–µ–Ω—ã –∫ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–º—É —Ä–∞–∑–º–µ—Ä—É (–Ω–∞–ø—Ä–∏–º–µ—Ä, 224√ó224 –ø–∏–∫—Å–µ–ª–µ–π),\n",
    "- –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã (–∑–Ω–∞—á–µ–Ω–∏—è –ø–∏–∫—Å–µ–ª–µ–π –ø—Ä–∏–≤–µ–¥–µ–Ω—ã –∫ –¥–∏–∞–ø–∞–∑–æ–Ω—É [0, 1] –∏–ª–∏ [-1, 1]).\n",
    "\n",
    "–≠—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ, –ø–æ—Ç–æ–º—É —á—Ç–æ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ **–Ω–µ –º–æ–≥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ —Ä–∞–∑–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞**, –∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è **—É—Å–∫–æ—Ä—è–µ—Ç –∏ —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä—É–µ—Ç –æ–±—É—á–µ–Ω–∏–µ**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a717ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ numpy (RGB + resize + –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è)\n",
    "\n",
    "TARGET_SIZE = (128, 128)\n",
    "\n",
    "def preprocess_pil_to_numpy(img_path: str, target_size=TARGET_SIZE) -> np.ndarray:\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img = img.resize(target_size)\n",
    "    arr = np.array(img, dtype=np.float32) / 255.0  # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤ [0, 1]\n",
    "    return arr  # shape: (H, W, 3)\n",
    "\n",
    "# —Ç–µ—Å—Ç\n",
    "sample_path = df[\"path\"].iloc[0]\n",
    "x = preprocess_pil_to_numpy(sample_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6578eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforms –¥–ª—è PyTorch\n",
    "\n",
    "torch_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
    "    transforms.ToTensor(), \n",
    "    # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é mean/std, –Ω–æ –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92d8c6f",
   "metadata": {},
   "source": [
    "## üîπ  –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤ (—á—Ç–æ–±—ã ‚Äú–ø—Ä–∏–º–µ—Ä–æ–≤ –±—ã–ª–æ +- –ø–æ—Ä–æ–≤–Ω—É‚Äù)\n",
    "\n",
    "–í —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è **–¥–∏—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã**: –æ–¥–Ω–∏ –ø–æ—Ä–æ–¥—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã —Å–æ—Ç–Ω—è–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –¥—Ä—É–≥–∏–µ ‚Äî –≤—Å–µ–≥–æ –¥–µ—Å—è—Ç–∫–æ–º. –≠—Ç–æ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ —Ç–æ–º—É, —á—Ç–æ –º–æ–¥–µ–ª—å **¬´—É—á–∏—Ç—Å—è –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å¬ª —Ä–µ–¥–∫–∏–µ –∫–ª–∞—Å—Å—ã**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15289614",
   "metadata": {},
   "source": [
    "###  –î–ª—è RandomForest (sklearn):\n",
    "\n",
    "–î–æ–±–∞–≤—å—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä `class_weight=\"balanced\"` –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –º–æ–¥–µ–ª–∏ ‚Äî —ç—Ç–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤–∑–≤–µ—Å–∏—Ç –æ—à–∏–±–∫–∏ –Ω–∞ —Ä–µ–¥–∫–∏—Ö –∫–ª–∞—Å—Å–∞—Ö —Å–∏–ª—å–Ω–µ–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ffcce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d876c0bb",
   "metadata": {},
   "source": [
    "### –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ ‚Äú—á—Ç–æ–±—ã –ø–æ—Ä–æ–≤–Ω—É‚Äù = WeightedRandomSampler\n",
    "–ß—Ç–æ–±—ã –∫–ª–∞—Å—Å—ã –≤—Å—Ç—Ä–µ—á–∞–ª–∏—Å—å –ø—Ä–∏–º–µ—Ä–Ω–æ –æ–¥–∏–Ω–∞–∫–æ–≤–æ –≤ –æ–±—É—á–µ–Ω–∏–∏ ‚Äî –¥–µ–ª–∞–π —Å–µ–º–ø–ª–∏–Ω–≥ —á–µ—Ä–µ–∑ WeightedRandomSampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c91c6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " –î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: 967 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, 10 –∫–ª–∞—Å—Å–æ–≤\n",
      " DataLoader —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –≥–æ—Ç–æ–≤!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "# 1. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.RandomErasing(p=0.3, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=\"dataset\", transform=train_transform)\n",
    "\n",
    "# 3. –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ —á–µ—Ä–µ–∑ —Å–µ–º–ø–ª–µ—Ä\n",
    "targets = torch.tensor(dataset.targets) \n",
    "class_count = torch.bincount(targets)\n",
    "class_weight = 1.0 / class_count.float()\n",
    "sample_weight = class_weight[targets]\n",
    "\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weight,\n",
    "    num_samples=len(dataset),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "# 4. –°–æ–∑–¥–∞—ë–º DataLoader\n",
    "train_loader = DataLoader(dataset, batch_size=32, sampler=sampler, num_workers=2)\n",
    "\n",
    "print(f\" –î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: {len(dataset)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, {len(dataset.classes)} –∫–ª–∞—Å—Å–æ–≤\")\n",
    "print(f\" DataLoader —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –≥–æ—Ç–æ–≤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9d6eb9",
   "metadata": {},
   "source": [
    "### –î–ª—è YOLOv8-cls (Ultralytics)\n",
    "–í YOLOv8 –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –æ–±—ã—á–Ω–æ ‚Äú–µ—Å—Ç‚Äù —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫, –∞ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫—É —á–∞—â–µ —Ä–µ—à–∞—é—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–∫–æ–π –¥–∞–Ω–Ω—ã—Ö (–æ–≤–µ—Ä—Å—ç–º–ø–ª–∏–Ω–≥ —Ä–µ–¥–∫–∏—Ö –∫–ª–∞—Å—Å–æ–≤ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ–º/–¥–æ–ø-–∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è–º–∏) –∏–ª–∏ —Å–≤–æ–∏–º–∏ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞–º–∏, –ø–æ—Ç–æ–º—É —á—Ç–æ ‚Äú—Å–∫–µ–π–ª–µ—Ä‚Äù –∫–∞–∫ –≤ sklearn —Ç–∞–º –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è ‚Äî –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è/–ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ —Å–ø—Ä—è—Ç–∞–Ω—ã –≤–Ω—É—Ç—Ä–∏ –ø–∞–π–ø–ª–∞–π–Ω–∞.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c523c2be",
   "metadata": {},
   "source": [
    "## üîπ –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π \n",
    "\n",
    "–ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è ‚Äî —ç—Ç–æ **–∫–ª—é—á–µ–≤–æ–π –ø—Ä–∏—ë–º** –≤ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–º –∑—Ä–µ–Ω–∏–∏, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –æ–±—ä—ë–º –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –ø–æ–≤—ã—Å–∏—Ç—å —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –∫ –≤–∞—Ä–∏–∞—Ü–∏—è–º –≤–æ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.\n",
    "\n",
    "–¶–µ–ª—å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ ‚Äî **—Å–º–æ–¥–µ–ª–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è —Å—ä—ë–º–∫–∏**, —Ç–∞–∫–∏–µ –∫–∞–∫:\n",
    "- –î—Ä—É–≥–æ–π —Ä–∞–∫—É—Ä—Å (–ø–æ–≤–æ—Ä–æ—Ç, –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ),\n",
    "- –ò–∑–º–µ–Ω—ë–Ω–Ω–æ–µ –æ—Å–≤–µ—â–µ–Ω–∏–µ (—è—Ä–∫–æ—Å—Ç—å, –∫–æ–Ω—Ç—Ä–∞—Å—Ç),\n",
    "- –ß–∞—Å—Ç–∏—á–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ –æ–±—ä–µ–∫—Ç–∞ (—Å–ª—É—á–∞–π–Ω–æ–µ —Å—Ç–∏—Ä–∞–Ω–∏–µ),\n",
    "- –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Ü–≤–µ—Ç–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (—á—ë—Ä–Ω–æ-–±–µ–ª—ã–π —Ä–µ–∂–∏–º).\n",
    "\n",
    "–≠—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç –º–æ–¥–µ–ª–∏ **–Ω–µ –ø–µ—Ä–µ–æ–±—É—á–∞—Ç—å—Å—è** –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã, –∞ **–Ω–∞—É—á–∏—Ç—å—Å—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å —Å—É—Ç—å –æ–±—ä–µ–∫—Ç–∞**.\n",
    "\n",
    "### –û—Å–Ω–æ–≤–Ω—ã–µ –≤–∏–¥—ã –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
    "\n",
    "| –¢–∏–ø –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ | –û–ø–∏—Å–∞–Ω–∏–µ | –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è |\n",
    "|------------------|--------|----------------------|\n",
    "| **–ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ** | –ó–µ—Ä–∫–∞–ª—å–Ω–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–π –æ—Å–∏. | –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ (–ª–∏—Ü–∞, —Å–æ–±–∞–∫–∏, –∞–≤—Ç–æ–º–æ–±–∏–ª–∏). |\n",
    "| **–ü–æ–≤–æ—Ä–æ—Ç** | –ü–æ–≤–æ—Ä–æ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ —Å–ª—É—á–∞–π–Ω—ã–π —É–≥–æ–ª –≤ –∑–∞–¥–∞–Ω–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ. | –ò–º–∏—Ç–∏—Ä—É–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–µ —É–≥–ª–∞ —Å—ä—ë–º–∫–∏. |\n",
    "| **–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–≤–µ—Ç–∞** | –°–ª—É—á–∞–π–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —è—Ä–∫–æ—Å—Ç–∏, –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞, –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç–∏ –∏ –æ—Ç—Ç–µ–Ω–∫–∞. | –ú–æ–¥–µ–ª–∏—Ä—É–µ—Ç —Ä–∞–∑–Ω—ã–µ —É—Å–ª–æ–≤–∏—è –æ—Å–≤–µ—â–µ–Ω–∏—è. |\n",
    "| **–ß—ë—Ä–Ω–æ-–±–µ–ª—ã–π —Ä–µ–∂–∏–º** | –°–ª—É—á–∞–π–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –≥—Ä–∞–¥–∞—Ü–∏–∏ —Å–µ—Ä–æ–≥–æ. | –ü–æ–≤—ã—à–∞–µ—Ç —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ —Ü–≤–µ—Ç–æ–≤—ã–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞–º. |\n",
    "| **–°–ª—É—á–∞–π–Ω–æ–µ —Å—Ç–∏—Ä–∞–Ω–∏–µ (Random Erasing)** | –ó–∞–∫—Ä–∞—à–∏–≤–∞–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–æ–≥–æ —É—á–∞—Å—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á—ë—Ä–Ω—ã–º —Ü–≤–µ—Ç–æ–º. | –ò–º–∏—Ç–∏—Ä—É–µ—Ç –ø–æ—Ç–µ—Ä—é —á–∞—Å—Ç–∏ –æ–±—ä–µ–∫—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∑–∞ –∫—É—Å—Ç–æ–º). |\n",
    "\n",
    "### –ü–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "\n",
    "–î–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É `torchvision.transforms`, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —É–¥–æ–±–Ω—ã–µ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã.\n",
    "\n",
    "# –ü–æ–ª—É—á–∞–µ–º –≤ –∏—Ç–æ–≥–µ –±–æ–ª—å—à–æ–π —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å—ç—Ç dataset_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f837c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (with aug): dataset_train_aug\n",
      "Test (clean): dataset_test_clean\n",
      "Train orig: 773 Test: 194\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TARGET_SIZE = (128, 128)\n",
    "\n",
    "DATASET_DIR = Path(\"dataset\")\n",
    "TRAIN_AUG_DIR = Path(\"dataset_train_aug\")   # train = –æ—Ä–∏–≥–∏–Ω–∞–ª—ã train + –∏—Ö –∞—É–≥–º–µ–Ω—Ç—ã\n",
    "TEST_CLEAN_DIR = Path(\"dataset_test_clean\") # test = —Ç–æ–ª—å–∫–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—ã test\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n",
    "\n",
    "# 1) –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–≤\n",
    "rows = []\n",
    "for class_dir in sorted([p for p in DATASET_DIR.iterdir() if p.is_dir()]):\n",
    "    label = class_dir.name\n",
    "    for img_path in class_dir.rglob(\"*\"):\n",
    "        if img_path.suffix.lower() in IMG_EXTS:\n",
    "            rows.append({\"path\": str(img_path), \"label\": label})\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# 2) Split –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–≤\n",
    "train_df, test_df = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df[\"label\"]\n",
    ")\n",
    "\n",
    "def reset_dir(p: Path):\n",
    "    if p.exists():\n",
    "        shutil.rmtree(p)\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def copy_split(df_part: pd.DataFrame, out_root: Path):\n",
    "    for _, row in df_part.iterrows():\n",
    "        src = Path(row[\"path\"])\n",
    "        label = row[\"label\"]\n",
    "        (out_root / label).mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy2(src, out_root / label / src.name)\n",
    "\n",
    "reset_dir(TRAIN_AUG_DIR)\n",
    "reset_dir(TEST_CLEAN_DIR)\n",
    "\n",
    "# 3) –ö–ª–∞–¥—ë–º –æ—Ä–∏–≥–∏–Ω–∞–ª—ã: train -> TRAIN_AUG_DIR, test -> TEST_CLEAN_DIR\n",
    "copy_split(train_df, TRAIN_AUG_DIR)\n",
    "copy_split(test_df, TEST_CLEAN_DIR)\n",
    "\n",
    "# 4) –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ (–¢–û–õ–¨–ö–û –î–õ–Ø TRAIN)\n",
    "augment = transforms.Compose([\n",
    "    transforms.Resize(TARGET_SIZE),\n",
    "    transforms.RandomRotation(degrees=20),\n",
    "    transforms.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25),\n",
    "    transforms.RandomGrayscale(p=0.25),  # 25% –±—É–¥—É—Ç —á/–±\n",
    "])\n",
    "\n",
    "def add_black_square(pil_img: Image.Image, max_frac=0.35) -> Image.Image:\n",
    "    img = pil_img.copy()\n",
    "    w, h = img.size\n",
    "    rw = int(w * random.uniform(0.1, max_frac))\n",
    "    rh = int(h * random.uniform(0.1, max_frac))\n",
    "    x0 = random.randint(0, max(0, w - rw))\n",
    "    y0 = random.randint(0, max(0, h - rh))\n",
    "    arr = np.array(img)\n",
    "    arr[y0:y0+rh, x0:x0+rw, :] = 0\n",
    "    return Image.fromarray(arr)\n",
    "\n",
    "def augment_train_only(train_df: pd.DataFrame, copies_per_image=2):\n",
    "    for _, row in train_df.iterrows():\n",
    "        src_path = Path(row[\"path\"])\n",
    "        label = row[\"label\"]\n",
    "        out_class_dir = TRAIN_AUG_DIR / label\n",
    "\n",
    "        for k in range(copies_per_image):\n",
    "            img = Image.open(src_path).convert(\"RGB\")\n",
    "            img = augment(img)\n",
    "            img = add_black_square(img)\n",
    "            img.save(out_class_dir / f\"{src_path.stem}_aug{k}{src_path.suffix}\")\n",
    "\n",
    "augment_train_only(train_df, copies_per_image=2)\n",
    "\n",
    "print(\"Train (with aug):\", TRAIN_AUG_DIR)\n",
    "print(\"Test (clean):\", TEST_CLEAN_DIR)\n",
    "print(\"Train orig:\", len(train_df), \"Test:\", len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37bc7e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ—Å–ª–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏: 2319\n",
      "label\n",
      "Beagle                240\n",
      "Boxer                 240\n",
      "Bulldog               240\n",
      "Poodle                240\n",
      "Yorkshire_Terrier     240\n",
      "Dachshund             231\n",
      "German_Shepherd       228\n",
      "Labrador_Retriever    228\n",
      "Golden_Retriever      219\n",
      "Rottweiler            213\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç\n",
    "\n",
    "rows_aug = []\n",
    "for class_dir in sorted([p for p in TRAIN_AUG_DIR.iterdir() if p.is_dir()]):\n",
    "    label = class_dir.name\n",
    "    for img_path in class_dir.rglob(\"*\"):\n",
    "        if img_path.suffix.lower() in IMG_EXTS:\n",
    "            rows_aug.append({\"path\": str(img_path), \"label\": label})\n",
    "\n",
    "df_aug = pd.DataFrame(rows_aug)\n",
    "print(\"–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ—Å–ª–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏:\", len(df_aug))\n",
    "print(df_aug[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a5e727",
   "metadata": {},
   "source": [
    "## üîπ Train/test split + –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤\n",
    "–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ (stratify)\n",
    "–ó–∞—á–µ–º: —á—Ç–æ–±—ã –¥–æ–ª–∏ –∫–ª–∞—Å—Å–æ–≤ –≤ train/test –±—ã–ª–∏ –ø–æ—Ö–æ–∂–∏.\n",
    "\n",
    "–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "–ï—Å—Ç—å 2 –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–∞:\n",
    "\n",
    "WeightedRandomSampler (–¥–ª—è DataLoader –≤ PyTorch) ‚Äî –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —á–∞—â–µ –ø–æ–¥–±–∏—Ä–∞—Ç—å —Ä–µ–¥–∫–∏–µ –∫–ª–∞—Å—Å—ã.\n",
    "\n",
    "class_weight (–¥–ª—è sklearn –º–æ–¥–µ–ª–µ–π) ‚Äî —à—Ç—Ä–∞—Ñ–æ–≤–∞—Ç—å –æ—à–∏–±–∫–∏ –ø–æ —Ä–µ–¥–∫–∏–º –∫–ª–∞—Å—Å–∞–º —Å–∏–ª—å–Ω–µ–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d75bb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1855 Test: 464\n",
      "Train class counts:\n",
      " label\n",
      "Yorkshire_Terrier     192\n",
      "Beagle                192\n",
      "Bulldog               192\n",
      "Boxer                 192\n",
      "Poodle                192\n",
      "Dachshund             185\n",
      "Labrador_Retriever    182\n",
      "German_Shepherd       182\n",
      "Golden_Retriever      175\n",
      "Rottweiler            171\n",
      "Name: count, dtype: int64\n",
      "Test class counts:\n",
      " label\n",
      "Beagle                48\n",
      "Yorkshire_Terrier     48\n",
      "Poodle                48\n",
      "Bulldog               48\n",
      "Boxer                 48\n",
      "Labrador_Retriever    46\n",
      "Dachshund             46\n",
      "German_Shepherd       46\n",
      "Golden_Retriever      44\n",
      "Rottweiler            42\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    df_aug,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df_aug[\"label\"]\n",
    ")\n",
    "\n",
    "print(\"Train:\", len(train_df), \"Test:\", len(test_df))\n",
    "print(\"Train class counts:\\n\", train_df[\"label\"].value_counts())\n",
    "print(\"Test class counts:\\n\", test_df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb698ad",
   "metadata": {},
   "source": [
    "## üîπ  –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∑–∞–¥–∞—á –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è\n",
    "\n",
    "| –ó–∞–¥–∞—á–∞ | –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –º–æ–¥–µ–ª–∏ | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |\n",
    "|--------|------------------|-------------------|\n",
    "| **–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è** | ResNet, EfficientNet, Vision Transformer (ViT), **YOLOv8-cls** | –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –Ω–∞ –≤—Å—ë–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ |\n",
    "| **–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤** | YOLOv8, Faster R-CNN, SSD | –ù—É–∂–Ω—ã –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∏ –∫–ª–∞—Å—Å –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ |\n",
    "| **–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è** | U-Net, Mask R-CNN, YOLOv8-seg | –¢—Ä–µ–±—É–µ—Ç—Å—è —Ç–æ—á–Ω–æ–µ –≤—ã–¥–µ–ª–µ–Ω–∏–µ –≥—Ä–∞–Ω–∏—Ü –æ–±—ä–µ–∫—Ç–∞ |\n",
    "| **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π** | Stable Diffusion, GAN | –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π |\n",
    "| **–ü–æ–≤—ã—à–µ–Ω–∏–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è** | ESRGAN, SRCNN | –£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π |\n",
    "\n",
    "> –î–ª—è –∑–∞–¥–∞—á –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–∞ —á–µ–º–ø–∏–æ–Ω–∞—Ç–µ **—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –Ω–∞—á–∏–Ω–∞—Ç—å —Å YOLOv8-cls –∏–ª–∏ EfficientNet-B0**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e61407b",
   "metadata": {},
   "source": [
    "### üîπ –ú–æ–¥–µ–ª—å 1: RandomForest –ø–æ ¬´—á–∏—Å–ª–∞–º¬ª (–ø–∏–∫—Å–µ–ª–∏ -> –≤–µ–∫—Ç–æ—Ä)\n",
    "–ò–¥–µ—è: –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É \n",
    "128√ó128√ó3 –≤ –≤–µ–∫—Ç–æ—Ä –¥–ª–∏–Ω—ã 128‚àó128‚àó3 –∏ –æ–±—É—á–∏—Ç—å RandomForest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1a18ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Beagle': 0, 'Boxer': 1, 'Bulldog': 2, 'Dachshund': 3, 'German_Shepherd': 4, 'Golden_Retriever': 5, 'Labrador_Retriever': 6, 'Poodle': 7, 'Rottweiler': 8, 'Yorkshire_Terrier': 9}\n"
     ]
    }
   ],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 5A: –∫–æ–¥–∏—Ä—É–µ–º –∫–ª–∞—Å—Å—ã —á–∏—Å–ª–∞–º–∏\n",
    "classes = sorted(train_df[\"label\"].unique())\n",
    "class_to_id = {c: i for i, c in enumerate(classes)}\n",
    "id_to_class = {i: c for c, i in class_to_id.items()}\n",
    "\n",
    "train_df = train_df.copy()\n",
    "test_df = test_df.copy()\n",
    "train_df[\"y\"] = train_df[\"label\"].map(class_to_id)\n",
    "test_df[\"y\"] = test_df[\"label\"].map(class_to_id)\n",
    "\n",
    "print(class_to_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f155589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1855, 49152) (1855,)\n"
     ]
    }
   ],
   "source": [
    "# –¥–µ–ª–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è sklearn \n",
    "\n",
    "def build_X_y(df_in: pd.DataFrame, target_size=TARGET_SIZE):\n",
    "    X_list, y_list = [], []\n",
    "    for _, row in df_in.iterrows():\n",
    "        arr = preprocess_pil_to_numpy(row[\"path\"], target_size=target_size)  # (H,W,3) float32 [0..1]\n",
    "        feat = arr.reshape(-1) \n",
    "        X_list.append(feat)\n",
    "        y_list.append(int(row[\"y\"]))\n",
    "    return np.stack(X_list), np.array(y_list)\n",
    "\n",
    "X_train, y_train = build_X_y(train_df)\n",
    "X_test, y_test = build_X_y(test_df)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7494c73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8836206896551724\n",
      "F1 macro: 0.883577743138486\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            Beagle       0.93      0.85      0.89        48\n",
      "             Boxer       0.81      0.90      0.85        48\n",
      "           Bulldog       0.98      0.88      0.92        48\n",
      "         Dachshund       0.76      0.96      0.85        46\n",
      "   German_Shepherd       0.88      0.91      0.89        46\n",
      "  Golden_Retriever       0.86      0.84      0.85        44\n",
      "Labrador_Retriever       0.98      0.91      0.94        46\n",
      "            Poodle       0.97      0.73      0.83        48\n",
      "        Rottweiler       0.83      0.90      0.86        42\n",
      " Yorkshire_Terrier       0.92      0.96      0.94        48\n",
      "\n",
      "          accuracy                           0.88       464\n",
      "         macro avg       0.89      0.88      0.88       464\n",
      "      weighted avg       0.89      0.88      0.88       464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForest –æ–±—É—á–µ–Ω–∏–µ\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"  # –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –≤–Ω—É—Ç—Ä–∏ –º–æ–¥–µ–ª–∏\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "pred_rf = rf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_rf))\n",
    "print(\"F1 macro:\", f1_score(y_test, pred_rf, average=\"macro\"))\n",
    "print(classification_report(y_test, pred_rf, target_names=classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce892794",
   "metadata": {},
   "source": [
    "## üîπ –ú–æ–¥–µ–ª—å 2: Logistic Regression (–µ—â—ë –æ–¥–∏–Ω baseline –ø–æ —á–∏—Å–ª–∞–º)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab1eccb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7931034482758621\n",
      "F1 macro: 0.7937177652126735\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            Beagle       0.84      0.75      0.79        48\n",
      "             Boxer       0.78      0.83      0.81        48\n",
      "           Bulldog       0.82      0.75      0.78        48\n",
      "         Dachshund       0.65      0.85      0.74        46\n",
      "   German_Shepherd       0.89      0.87      0.88        46\n",
      "  Golden_Retriever       0.83      0.89      0.86        44\n",
      "Labrador_Retriever       0.73      0.78      0.76        46\n",
      "            Poodle       0.74      0.71      0.72        48\n",
      "        Rottweiler       0.85      0.69      0.76        42\n",
      " Yorkshire_Terrier       0.87      0.81      0.84        48\n",
      "\n",
      "          accuracy                           0.79       464\n",
      "         macro avg       0.80      0.79      0.79       464\n",
      "      weighted avg       0.80      0.79      0.79       464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  LogisticRegression (—á–∞—Å—Ç–æ —Å–∏–ª—å–Ω–µ–µ, —á–µ–º –∫–∞–∂–µ—Ç—Å—è, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –∏—Ç–µ—Ä–∞—Ü–∏–π)\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=None\n",
    ")\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "pred_lr = lr.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_lr))\n",
    "print(\"F1 macro:\", f1_score(y_test, pred_lr, average=\"macro\"))\n",
    "print(classification_report(y_test, pred_lr, target_names=classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19ef236",
   "metadata": {},
   "source": [
    "## üîπ YOLO –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (YOLO-cls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735f922c",
   "metadata": {},
   "source": [
    "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∏–∑ dataset_aug\n",
    "–°–µ–π—á–∞—Å: dataset_aug/Beagle/*.jpg, dataset_aug/Boxer/*.jpg –∏ —Ç.–ø.\n",
    "YOLO-cls –æ–∂–∏–¥–∞–µ—Ç —Ç–∞–∫:\n",
    "dataset_yolo_cls/train/<class>/*.jpg –∏ dataset_yolo_cls/val/<class>/*.jpg (–∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ test).\n",
    "‚Äã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47437140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO dataset ready: dataset_yolo_cls\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "SRC_TRAIN = Path(\"dataset_train_aug\")\n",
    "SRC_VAL = Path(\"dataset_test_clean\")   # —á–∏—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞\n",
    "DST = Path(\"dataset_yolo_cls\")\n",
    "\n",
    "TRAIN_DIR = DST / \"train\"\n",
    "VAL_DIR = DST / \"val\"\n",
    "\n",
    "if DST.exists():\n",
    "    shutil.rmtree(DST)\n",
    "TRAIN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "VAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def copy_tree(src_root: Path, dst_root: Path):\n",
    "    for class_dir in src_root.iterdir():\n",
    "        if not class_dir.is_dir():\n",
    "            continue\n",
    "        out = dst_root / class_dir.name\n",
    "        out.mkdir(parents=True, exist_ok=True)\n",
    "        for p in class_dir.glob(\"*\"):\n",
    "            if p.is_file():\n",
    "                shutil.copy2(p, out / p.name)\n",
    "\n",
    "copy_tree(SRC_TRAIN, TRAIN_DIR)\n",
    "copy_tree(SRC_VAL, VAL_DIR)\n",
    "\n",
    "print(\"YOLO dataset ready:\", DST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6793b8e",
   "metadata": {},
   "source": [
    "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ ultralytics\n",
    "YOLO –æ—Ç Ultralytics —Ç—Ä–µ–Ω–∏—Ä—É–µ—Ç—Å—è —á–µ—Ä–µ–∑ from ultralytics import YOLO –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–µ–∂–∏–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å yolo11n-cls.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54e91722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (8.3.243)\n",
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.248-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from ultralytics) (2.2.6)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from ultralytics) (3.10.7)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from ultralytics) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from ultralytics) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from ultralytics) (1.16.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from ultralytics) (2.9.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from ultralytics) (0.24.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from ultralytics) (7.1.3)\n",
      "Requirement already satisfied: polars>=0.20.0 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from ultralytics) (1.36.1)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from ultralytics) (2.0.18)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=3 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: polars-runtime-32==1.36.1 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from polars>=0.20.0->ultralytics) (1.36.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
      "Requirement already satisfied: filelock in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2025.12.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/veronikadenisenko/for_hacks/myenv/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
      "Downloading ultralytics-8.3.248-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ultralytics\n",
      "  Attempting uninstall: ultralytics\n",
      "    Found existing installation: ultralytics 8.3.243\n",
      "    Uninstalling ultralytics-8.3.243:\n",
      "      Successfully uninstalled ultralytics-8.3.243\n",
      "Successfully installed ultralytics-8.3.248\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1288f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34eae97",
   "metadata": {},
   "source": [
    "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö ‚Äî —ç—Ç–æ —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –º–æ–¥–µ–ª—å ‚Äú–ø—Ä–æ–π–¥—ë—Ç‚Äù –ø–æ –≤—Å–µ–º—É train‚Äë–Ω–∞–±–æ—Ä—É, –Ω–æ –≤ Ultralytics –æ–±—ã—á–Ω–æ —Å—Ç–∞–≤—è—Ç epochs —Å –∑–∞–ø–∞—Å–æ–º –∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç `patience` (early stopping), —á—Ç–æ–±—ã –æ–±—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–∏–ª–æ—Å—å, –∫–æ–≥–¥–∞ –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ val –ø–µ—Ä–µ—Å—Ç–∞–ª–∏ —É–ª—É—á—à–∞—Ç—å—Å—è.\n",
    "\n",
    "## –°–∫–æ–ª—å–∫–æ —ç–ø–æ—Ö —Å—Ç–∞–≤–∏—Ç—å  (–ø—Ä–∞–∫—Ç–∏—á–Ω–æ)\n",
    "- –î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —á–µ—Ä–Ω–æ–≤–æ–≥–æ –ø—Ä–æ–≥–æ–Ω–∞: **10‚Äì30 —ç–ø–æ—Ö** (—á—Ç–æ–±—ã –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç –∏ –º–µ—Ç—Ä–∏–∫–∏ —Ä–∞—Å—Ç—É—Ç).\n",
    "- –î–ª—è ‚Äú–Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ‚Äù –æ–±—É—á–µ–Ω–∏—è: —á–∞—Å—Ç–æ —Å—Ç–∞–≤—è—Ç **100‚Äì300 —ç–ø–æ—Ö**, –∞ –æ—Å—Ç–∞–Ω–æ–≤–∫—É –¥–æ–≤–µ—Ä—è—é—Ç `patience`, —á—Ç–æ–±—ã –Ω–µ —Ç—Ä–∞—Ç–∏—Ç—å –ª–∏—à–Ω–µ–µ –≤—Ä–µ–º—è –∏ –Ω–µ —É–π—Ç–∏ –≤ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ.\n",
    "- –ï—Å–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç –º–∞–ª–µ–Ω—å–∫–∏–π/–ø—Ä–æ—Å—Ç–æ–π, –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –≤—ã–π—Ç–∏ –Ω–∞ –ø–ª–∞—Ç–æ –±—ã—Å—Ç—Ä–æ ‚Äî —Ç–æ–≥–¥–∞ `patience` (–Ω–∞–ø—Ä–∏–º–µ—Ä 10‚Äì20) —Å—Ä–∞–±–æ—Ç–∞–µ—Ç —Ä–∞–Ω—å—à–µ, –∏ —Ä–µ–∞–ª—å–Ω—ã–µ —ç–ø–æ—Ö–∏ –±—É–¥—É—Ç –º–µ–Ω—å—à–µ –∑–∞–¥–∞–Ω–Ω—ã—Ö.\n",
    "\n",
    "## –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä—è–º–æ –≤ –∫–æ–¥–µ\n",
    "1) ‚Äú–ë—ã—Å—Ç—Ä–æ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ‚Äù:\n",
    "```python\n",
    "results = model.train(\n",
    "    data=\"dataset_yolo_cls\",\n",
    "    epochs=50,\n",
    "    patience=10,   # –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è, –µ—Å–ª–∏ –Ω–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è 10 —ç–ø–æ—Ö \n",
    "    imgsz=224,\n",
    "    batch=32\n",
    ")\n",
    "```\n",
    "\n",
    "2) ‚Äú–° –∑–∞–ø–∞—Å–æ–º, –ø—É—Å—Ç—å —Å–∞–º–∞ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è‚Äù:\n",
    "```python\n",
    "results = model.train(\n",
    "    data=\"dataset_yolo_cls\",\n",
    "    epochs=300,    # —á–∞—Å—Ç—ã–π —Å—Ç–∞—Ä—Ç–æ–≤—ã–π –æ—Ä–∏–µ–Ω—Ç–∏—Ä \n",
    "    patience=20,\n",
    "    imgsz=224,\n",
    "    batch=32\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e0a9a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.248 üöÄ Python-3.12.6 torch-2.9.1 CPU (Apple M3)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=dataset_yolo_cls, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=2, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train6, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/Users/veronikadenisenko/Documents/Preparing_Rea2026/Module 1/–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/runs/classify/train6, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /Users/veronikadenisenko/Documents/Preparing_Rea2026/Module 1/–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/dataset_yolo_cls/train... found 2319 images in 10 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /Users/veronikadenisenko/Documents/Preparing_Rea2026/Module 1/–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/dataset_yolo_cls/val... found 194 images in 10 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 10                  -1  1    343050  ultralytics.nn.modules.head.Classify         [256, 10]                     \n",
      "YOLO11n-cls summary: 86 layers, 1,543,914 parameters, 1,543,914 gradients, 3.3 GFLOPs\n",
      "Transferred 234/236 items from pretrained weights\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 112.7¬±88.6 MB/s, size: 3.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/veronikadenisenko/Documents/Preparing_Rea2026/Module 1/–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/dataset_yolo_cls/train... 2319 images, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2319/2319 10.1Kit/s 0.2s.1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/veronikadenisenko/Documents/Preparing_Rea2026/Module 1/–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/dataset_yolo_cls/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 221.8¬±86.6 MB/s, size: 3.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/veronikadenisenko/Documents/Preparing_Rea2026/Module 1/–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/dataset_yolo_cls/val... 194 images, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 194/194 8.8Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/veronikadenisenko/Documents/Preparing_Rea2026/Module 1/–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/dataset_yolo_cls/val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/veronikadenisenko/Documents/Preparing_Rea2026/Module 1/–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/runs/classify/train6\u001b[0m\n",
      "Starting training for 2 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K        1/2         0G      1.859         15        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 73/73 1.4it/s 52.8s0.4ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.1it/s 1.9s0.9s\n",
      "                   all      0.933          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K        2/2         0G     0.6651         15        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 73/73 1.4it/s 50.7s0.4ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.2it/s 1.8s0.9s\n",
      "                   all      0.964          1\n",
      "\n",
      "2 epochs completed in 0.030 hours.\n",
      "Optimizer stripped from /Users/veronikadenisenko/Documents/Preparing_Rea2026/Module 1/–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/runs/classify/train6/weights/last.pt, 3.2MB\n",
      "Optimizer stripped from /Users/veronikadenisenko/Documents/Preparing_Rea2026/Module 1/–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/runs/classify/train6/weights/best.pt, 3.2MB\n",
      "\n",
      "Validating /Users/veronikadenisenko/Documents/Preparing_Rea2026/Module 1/–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/runs/classify/train6/weights/best.pt...\n",
      "Ultralytics 8.3.248 üöÄ Python-3.12.6 torch-2.9.1 CPU (Apple M3)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,538,834 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /Users/veronikadenisenko/Documents/Preparing_Rea2026/Module 1/–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/dataset_yolo_cls/train... found 2319 images in 10 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /Users/veronikadenisenko/Documents/Preparing_Rea2026/Module 1/–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/dataset_yolo_cls/val... found 194 images in 10 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 2.1it/s 1.9s1.0s\n",
      "                   all      0.964          1\n",
      "Speed: 0.0ms preprocess, 8.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/veronikadenisenko/Documents/Preparing_Rea2026/Module 1/–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/runs/classify/train6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "DST = Path(\"dataset_yolo_cls\")\n",
    "\n",
    "model = YOLO(\"yolo11n-cls.pt\")  # –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ \n",
    "\n",
    "results = model.train(\n",
    "    data=str(DST),     # –∫–æ—Ä–µ–Ω—å, –≥–¥–µ –ª–µ–∂–∞—Ç train/val\n",
    "    epochs=2,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    patience=10        # —Ä–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞, –µ—Å–ª–∏ –º–µ—Ç—Ä–∏–∫–∞ –Ω–µ —É–ª—É—á—à–∞–µ—Ç—Å—è\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8a5d8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.248 üöÄ Python-3.12.6 torch-2.9.1 CPU (Apple M3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-cls summary (fused): 47 layers, 1,538,834 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /Users/veronikadenisenko/Documents/Preparing_Rea2026/Module 1/–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/dataset_yolo_cls/train... found 2319 images in 10 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /Users/veronikadenisenko/Documents/Preparing_Rea2026/Module 1/–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/dataset_yolo_cls/val... found 194 images in 10 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 157.4¬±94.7 MB/s, size: 3.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/veronikadenisenko/Documents/Preparing_Rea2026/Module 1/–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/dataset_yolo_cls/val... 194 images, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 194/194 907.1Kit/s 0.0s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13/13 5.3it/s 2.4s0.2s\n",
      "                   all      0.964          1\n",
      "Speed: 0.0ms preprocess, 10.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/veronikadenisenko/Documents/Preparing_Rea2026/Module 1/–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/runs/classify/val4\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x3374c1f40>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.9819587767124176\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.9639175534248352, 'metrics/accuracy_top5': 1.0, 'fitness': 0.9819587767124176}\n",
       "save_dir: PosixPath('/Users/veronikadenisenko/Documents/Preparing_Rea2026/Module 1/–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/runs/classify/val4')\n",
       "speed: {'preprocess': 0.0006806288924447463, 'inference': 10.898079252545303, 'loss': 4.4886620184790686e-05, 'postprocess': 0.00011855677867154639}\n",
       "task: 'classify'\n",
       "top1: 0.9639175534248352\n",
       "top5: 1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_res = model.val(data=str(DST))\n",
    "val_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9903e3d",
   "metadata": {},
   "source": [
    "–ß—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç –∫–∞–∂–¥–∞—è –º–µ—Ç—Ä–∏–∫–∞:\n",
    "Accuracy: –¥–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π (top‚Äë1 –ø–æ–ø–∞–¥–∞–Ω–∏–µ).\n",
    "\n",
    "Top‚Äë5 accuracy: –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∫–ª–∞—Å—Å –≤ —Ç–æ–ø‚Äë5 –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ (–≤–∞–∂–Ω–æ –ø—Ä–∏ –±–æ–ª—å—à–æ–º —á–∏—Å–ª–µ –∫–ª–∞—Å—Å–æ–≤).\n",
    "‚Äã\n",
    "\n",
    "Precision (macro): ‚Äú–∫–æ–≥–¥–∞ –º–æ–¥–µ–ª—å —Å–∫–∞–∑–∞–ª–∞ –∫–ª–∞—Å—Å, –Ω–∞—Å–∫–æ–ª—å–∫–æ —á–∞—Å—Ç–æ –ø—Ä–∞–≤–∞‚Äù, —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Å–∞–º –±–µ–∑ —É—á—ë—Ç–∞ —Ä–∞–∑–º–µ—Ä–∞ –∫–ª–∞—Å—Å–æ–≤.\n",
    "\n",
    "Recall (macro): ‚Äú—Å–∫–æ–ª—å–∫–æ –æ–±—ä–µ–∫—Ç–æ–≤ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ –º–æ–¥–µ–ª—å –Ω–∞—à–ª–∞‚Äù, —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Å–∞–º.\n",
    "\n",
    "F1 (macro): –±–∞–ª–∞–Ω—Å precision –∏ recall, —á–µ—Å—Ç–Ω–µ–µ –ø—Ä–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å–µ.\n",
    "\n",
    "Balanced accuracy: —Å—Ä–µ–¥–Ω–∏–π recall –ø–æ –∫–ª–∞—Å—Å–∞–º (–ø–æ–ª–µ–∑–Ω–æ –ø—Ä–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å–µ).\n",
    "\n",
    "Confusion matrix: –∫–∞–∫–∏–µ –∫–ª–∞—Å—Å—ã —Å –∫–∞–∫–∏–º–∏ –ø—É—Ç–∞—é—Ç—Å—è.\n",
    "\n",
    "ROC-AUC (ovr): –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –º–æ–¥–µ–ª—å —Ä–∞–Ω–∂–∏—Ä—É–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∫–ª–∞—Å—Å –≤—ã—à–µ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º (–Ω—É–∂–Ω—ã –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ –º–µ—Ç–∫–∏)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d345d719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val samples: 194 classes: 10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "VAL_DIR = Path(\"dataset_yolo_cls/val\")\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n",
    "\n",
    "# —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –∏ –∏—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ (–∏–∑ –ø–∞–ø–∫–∏)\n",
    "val_paths = []\n",
    "y_true_names = []\n",
    "\n",
    "for class_dir in sorted([p for p in VAL_DIR.iterdir() if p.is_dir()]):\n",
    "    for p in class_dir.rglob(\"*\"):\n",
    "        if p.is_file() and p.suffix.lower() in IMG_EXTS:\n",
    "            val_paths.append(str(p))\n",
    "            y_true_names.append(class_dir.name)\n",
    "\n",
    "# –¥–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –±–∞—Ç—á–∞–º–∏ (Ultralytics —Å–∞–º –±–∞—Ç—á–∏—Ç)\n",
    "pred_results = model.predict(source=val_paths, imgsz=224, verbose=False)\n",
    "\n",
    "# –ø—Ä–µ–≤—Ä–∞—â–∞–µ–º –≤ id-–º–µ—Ç–∫–∏\n",
    "name_to_id = {v: int(k) for k, v in model.names.items()}  # model.names: id->name \n",
    "n_classes = len(model.names)\n",
    "\n",
    "y_true = np.array([name_to_id[n] for n in y_true_names], dtype=int)\n",
    "\n",
    "y_pred = []\n",
    "y_proba = []\n",
    "\n",
    "for r in pred_results:\n",
    "    # probs —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤ + top1/top5 –∏ confidence \n",
    "    probs = r.probs\n",
    "    y_pred.append(int(probs.top1))                 # id top-1 –∫–ª–∞—Å—Å–∞ \n",
    "    y_proba.append(probs.data.cpu().numpy())       # –ø–æ–ª–Ω—ã–π –≤–µ–∫—Ç–æ—Ä –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π \n",
    "\n",
    "y_pred = np.array(y_pred, dtype=int)\n",
    "y_proba = np.stack(y_proba)\n",
    "\n",
    "print(\"val samples:\", len(y_true), \"classes:\", n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "167e18d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (top-1): 0.9639175257731959\n",
      "Balanced accuracy: 0.963391812865497\n",
      "Precision macro: 0.9659038901601831\n",
      "Recall macro: 0.963391812865497\n",
      "F1 macro: 0.9637080759724579\n",
      "F1 weighted: 0.9641120302554517\n",
      "Top-5 accuracy: 1.0\n",
      "ROC-AUC ovr macro: 0.998372353951755\n",
      "ROC-AUC ovr weighted: 0.9983765810561047\n",
      "\n",
      "Confusion matrix:\n",
      " [[20  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 20  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 20  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 18  0  0  0  0  1  0]\n",
      " [ 0  0  0  0 20  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 17  1  0  0  0]\n",
      " [ 0  0  0  0  3  0 16  0  0  0]\n",
      " [ 0  0  0  0  0  0  2 18  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 18  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 20]]\n",
      "\n",
      "Classification report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "            Beagle       1.00      1.00      1.00        20\n",
      "             Boxer       1.00      1.00      1.00        20\n",
      "           Bulldog       1.00      1.00      1.00        20\n",
      "         Dachshund       1.00      0.95      0.97        19\n",
      "   German_Shepherd       0.87      1.00      0.93        20\n",
      "  Golden_Retriever       1.00      0.94      0.97        18\n",
      "Labrador_Retriever       0.84      0.84      0.84        19\n",
      "            Poodle       1.00      0.90      0.95        20\n",
      "        Rottweiler       0.95      1.00      0.97        18\n",
      " Yorkshire_Terrier       1.00      1.00      1.00        20\n",
      "\n",
      "          accuracy                           0.96       194\n",
      "         macro avg       0.97      0.96      0.96       194\n",
      "      weighted avg       0.97      0.96      0.96       194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score,\n",
    "    precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report,\n",
    "    top_k_accuracy_score, roc_auc_score\n",
    ")\n",
    "\n",
    "print(\"Accuracy (top-1):\", accuracy_score(y_true, y_pred))\n",
    "print(\"Balanced accuracy:\", balanced_accuracy_score(y_true, y_pred))\n",
    "print(\"Precision macro:\", precision_score(y_true, y_pred, average=\"macro\", zero_division=0))\n",
    "print(\"Recall macro:\", recall_score(y_true, y_pred, average=\"macro\", zero_division=0))\n",
    "print(\"F1 macro:\", f1_score(y_true, y_pred, average=\"macro\", zero_division=0))\n",
    "print(\"F1 weighted:\", f1_score(y_true, y_pred, average=\"weighted\", zero_division=0))\n",
    "\n",
    "print(\"Top-5 accuracy:\", top_k_accuracy_score(y_true, y_proba, k=min(5, y_proba.shape[1])))\n",
    "\n",
    "# ROC-AUC –¥–ª—è –º—É–ª—å—Ç–∏–∫–ª–∞—Å—Å–∞ \n",
    "try:\n",
    "    print(\"ROC-AUC ovr macro:\", roc_auc_score(y_true, y_proba, multi_class=\"ovr\", average=\"macro\"))\n",
    "    print(\"ROC-AUC ovr weighted:\", roc_auc_score(y_true, y_proba, multi_class=\"ovr\", average=\"weighted\"))\n",
    "except Exception as e:\n",
    "    print(\"ROC-AUC error:\", e)\n",
    "\n",
    "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_true, y_pred, target_names=[model.names[i] for i in range(n_classes)]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
